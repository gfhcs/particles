
#### NEUESTE GEDANKEN:

Man könnte ein Bezahlsystem hinzufügen: Nodes wählen dann immer den Nachbarn für einen Auftrag aus, der das beste Preis-Rechenzeit-Verhältnis anbietet. Bevor der Nachbar die Berechnung beginnt, muss über eine Bank ein wähnungstransfer abgewickelt worden sein. Wenn man das einbaut, kann man die Software später mal (wenn man selber als großer, zuverlässiger Rechenknoten etabliert ist) rausgeben und quelloffen machen und sich trotzdem ne goldene Nase verdienen. Aber vermutlich klappt das nicht, denn man müsste dafür selber große Rechenkapazitäten haben, die man sich wohl bei Amazon mieten würde. Und dann würde jeder Hinz und Kunz bei Amazon mieten, oder die Leute würden immer direkt ihr Zeug bei Amazon aufsetzen. Andererseits: Normale Enduser wollen einfach nur mit dem Ding spielen und beeindruckende Dinge sehen. Dafür würden die auch Geld auf den Tisch legen...

Man sollte es so machen, dass die Eigenschaften, die wir pro Teilchen tracken, solche wie diese hier sind:

	Position
	Geschwindigkeit
	Masse
	Graviation
	Starke Kernkraft
	Schwache Kernkraft
	Elektromagnetische Wechselwirkung
	Teilchentyp (Elektron, Proton, Neutron, Wasserstoffatom, Alkoholmolekül)
	Chemische Reaktionen
	Nukleare Reaktionen
	Ko-/Adhesion von Molekülen
	
Es muss also Plugins geben, die spezifizieren, welche Datenfelder ein Teilchen hat und welche globalen Daten sie brauchen. Sie spezifizieren die durchzuführende Berechnung  (die den Zustand des Universums von einem Zeitpunkt zum nächsten updated) als Kernel, die pro Teilchen in Stufen ausgeführt werden. Pro Stufe werden also alle Teilchen mit dem Kernel geupdated, dann wird der Speicher für alle beteiligten Threads geflusht (barrier, damit alle dasselbe sehen) und dann wird die nächste Stufe gegeben. Dieses Verfahren eignet sich für alle oben beschriebenen Wechselwirkungen und erlaubt es, generische Propagatoren für die GPU, CPU und Netwerk zu bauen, die alle miteinander betrieben werden können. Die Kernel müssen so geschrieben sein, dass man sie auf verschiedene Arten verteilen kann: Entweder man partitioniert Teilchen und lässt eine Wechselwirkung von mehreren Knoten berechnen, oder man partitioniert Wechselwirkungen und lässt ein Teilchen von mehreren Knoten berechnen.
Es muss während der Simulation möglich sein, Propagatoren hinzuzufügen oder abzuziehen. Idealerweise ist die Kanalstruktur zwischen den Threads nicht zentralisiert, sondern peer-to-peer, d.h. Tim kann einen Knoten aufsetzen, der alle seine Rechner zu Hause bündelt und die gebündelten Daten mit Toms Zentralrechner teilt, der hin und wieder mal noch seinen Server mit einklinkt.  Die Simulation soll das Ergebnis eines jeden Zeitschritts in einen (blockierenden) Buffer von Zuständen schreiben. Aus dem mag man die Zustände dann herausnehmen, um daraus Bilder und Videos zu berechnen, sie auf die Platte zu speichern, oder im Netz weiter zu versenden. Das ganze Netz kann sich selbst load-balancen.

Schön wäre es, wenn die Zeitschritte eine adaptive Länge hätten (wenn nicht viel mit den Teilchen abgeht, kann das Intervall ja ruhig ein bischen länger sein). Außerdem sollte es möglich sein, zwischen zwei gegebenen Zeitschritten einen Zwischenschritt zu interpolieren.


Die Berechnung soll auf Knoten verteilt werden. Knoten können sein: CPU's, GPU's, entfernte Rechner. Außerdem gibt es Meta-Knoten, die all ihre Arbeit einfach auf andere Knoten verteilen. Man kann es auch so sehen, dass CPU's und einzelne Vektor-Lanes einer GPU Blätter im DAG sind, während Meta-Knoten innere Knoten im DAG sind. Der Nutzer soll die Knoten und ihre Verbindungen definieren. Er baut dabei einen DAG. Es gibt dabei zwei Kantentypen:  

Es gibt zwei Arten von Kanten: a ==> b heißt "Knoten a darf Aufträge für die aktuelle Iteration an Knoten b geben". 
							   b --> a heißt "Knoten a darf sich Informationen der vorherigen Iteration von Knoten b beschaffen".
							   
Ausgewählte Wurzelknoten (meistens genau einer) werden vom Nutzer bedient. Von ihnen gehen die Aufträge aus. Der DAG ist getaktet: Ein Knoten erhält einen Berechnungsauftrag. Entweder teilt er diesen auf seine ==> Nachfolger auf, oder er rechnet selber. Irgendwann braucht er Informationen über den Zwischenzustand der restlichen Knoten. Dann holt er sich (verteilt über seine --> Vorgänger) Informationen über die Auftragsergebnisse des restlichen Netzes. Erst wenn er die alle hat, fährt er mit dem Auftrag fort. Falls dem Knoten selbst eine solche Anfrage gestellt wird, versucht er sie (falls er selber ein Arbeiter ist) aus seinem Auftragszwischenergebnis zu entnehmen, oder er fragt bei seinen --> Vorgängern an. Das wiederholt sich, bis der Auftrag des Knotens abgeschlossen ist.
Man beachte, dass während einer Iteration Anfragen für eine vorangegangen Iteration immer über die --> Kanten laufen, während Anfragen für die aktuelle Iteration über ==> Kanten empfangen werden. Es darf keine ==> Zyklen geben, --> Zyklen sind erlaubt. Wenn a ==> b und a --> b, kann es nicht sein, dass a's Auftrag an b einfach von b durch Abfragen der Informationen von a beantwortet wird (was zu einem Deadlock führen würde): a fragt nach Daten für die aktuelle Iteration, wohingegen b von a nur Daten über die vorherige Iteration anfragen kann. Ein Knoten gibt also über eine --> Kante nur Informationen zu einem Auftrag weiter, wenn ihm dessen Beendigung über ==> Kanten gemeldet wurde.

Die Kanten werden wie gesagt vom Nutzer definiert, aber welche davon ein Knoten wie stark beansprucht, um Aufträge zu verteilen und Statusupdates zu sammeln, ist Sache des Knotens (der durch Zeitmessung Load-Balancing macht).
Man beachte, dass das Auftragsrouting mehr oder minder statisch ist: Ein Knoten geht immer davon aus, dass sein nächster Auftrag die selben Teilchen betreffen wird und fährt ohne weiteres abwarten sofort mit diesem fort, sobald der aktuelle abgeschlossen und über die --> Kanten die nötigen Informationen über den Zustand abgeholt sind. Das Ausbleiben von Aufträgen muss vom ==> Vorgänger aktiv signalisiert werden (z.B. weil dieser anders balancen will).
Einfache Daumenregeln: Über --> Kanten liefert ein Knoten nie Daten aus, für deren Berechnung er selber einen Auftrag vergeben hat, der noch nicht abgeschlossen wurde.
		Außerdem gilt: Eine Anforderung von Daten über eine --> Kante führt nie dazu, dass der Knoten etwas berechnet, oder einen Auftrag vergibt! Er wird höchstens feststellen, dass er die angeforderten Daten nicht hat und sie über seine --> Kanten anfordern.


Schön wäre es außerdem, wenn man verteilte Architektur als separate Komponente wiederverwenden könnte (z.B. um einen verteilten Raytracer zu implementieren...)

Um schnell was nettes zu haben, mit dem man ein bischen spielen kann, muss ich 
wohl davon ausgehen, dass alle Integratoren in den Knoten schon vorhanden 
sind. Richtig perfekt wird die Sache aber erst, wenn ich eine Particle-DSL 
erfinde, die den Übergang eines Teilchens von einem Zeitschritt zum nächsten 
beschreibt. Damit wäre für den Nutzer sehr viel hässliches Zeug weg 
abstrahiert und man könnte beliebige Integratoren sehr schnell einbauen und 
übers Netzwerk an fremde Knoten senden (die allerdings vermutlich LLVM und 
nvcc installiert haben müssen, falls sie die DSL *schnell* ausführen wollen). 
Ich bräuchte dann einen Compiler für die DSL und vermutlich auch eine Data 
Dependence Analyse (für die Snchronisation), aber das erscheint mir die Sache 
wert...

Phänomene, die man simulieren können soll:

Newton'sche Gravitation
chemische Rekationen
Explosionen
Raketentriebwerke
Nukleare Kettenreaktionen
Phasen im Leben eines Sterns
Glaxien samt schwarzer Löcher und Sterne mit Planeten und Monden
Wasserplanschen
Kuchenbacken
Feuer
Fischschwärme
Ameisenhaufen
Räuber-Beute-Modelle (Haie und Fische...)
Zelluläre Automaten
Festkörperkollisionen mit Deformierung
Aeordynamik
Biologische Zellen (z.B. Lipidmembran usw...)
Biologisches Wachstum nach DNA
Gehirnwachstum
Soziale Netzwerke (Entwicklung und Interaktion der Individuen einer Gesellschaft)
Wetter
Prozesse in einem Organsimus (z.B. Verteilung von Sauerstoff übers Blut, Stoffwechsel, Vireninfektionen, Medikamentengabe, ...)
Ausbreitung von Pflanzen und Tieren.


============= Ältere Gedanken: ==============


Einen abgeschmackten Prototypen, der um beliebige Partikel, Kräfte und 
Reaktionen erweiterbar ist, können wir mir aufgrund dieser Überlegungen bereits 
bauen. Es bleiben zwei Probleme:
1. In welcher Form stellen wir den Output der Simulation bereit, um ihn geeignet weiterzuverarbeiten.
	Antwort: Das Simulation-Objekt enthält immer nur die aktuelle Stützstelle. Die Daten werden sofort nach ihrer Berechnung in einen "Abnehmer" gedumpt. Solche Abnehmer könnten ein Wrapper für Festplatten oder ein Speicherstream sein, aber auch ein Display-Objekt, dass die Daten auf dem Bildschirm darstellt, sowie ein Video-Encoder, der ein Video der Simulation erstellt. Auf diese Weise sind nur dann große Speicherressourcen erforderlich, wenn die Simulation in ihrer Gesamtheit gespeichert werden soll. und z.B. nicht für die Erstellung eines Videos. Idealerweise sollten aber sogar mehrere Dump-Objekte bedient werden! Die Dump-Objekte entscheiden selbst, was sie mit der ihnen übergebenen Stützstelle anfangen wollen und sollten eigene Agenten sein!
	
2. Wie werden wir durch verteiltes Rechnen des großen Aufwandes Herr?
	Es soll möglich sein die Simulation auf mehrere Berechnungseinheiten zu verteilen. Ein ideales Szenario wäre: Lokal starte ich die Simulation auf meinem Rechner und erlaube ihr, 3 meiner 4 Prozessorkerne voll auszulasten, während der vierte nur entsprechend dessen sonstiger Last genutzt werden soll. Dann aktiviere ich das Lauschen am Netzwerk. Andere Rechner sollen sich darüber nun in die Simulation einklinken können und meinem Rechner Last abnehmen bzw. die Berechnung beschleunigen. Nach 8 Stunden entscheide ich, ins Bett zu gehen und fahre meinen Rechner herunter. Die anderen eingeklinkten merken das und rechnen munter weiter. Am Morgen fahre ich meinen Rechner wieder hoch und setze die Simulation fort, helfe also den anderen (von denen einige sich ebenfalls deaktiviert haben und zu denen neue dazugestoßen sind) wieder. Ich lasse auch meinen Zweitrechner mit einsteigen. Da der aber recht langsam ist, antwortet er zunächst zu langsam, weswegen mein Rechner seine Kommunikation zunächst an andere 
weiterleitet.
	Dann stürzt mein Zweitrechner wegen Überhitzung ohne Vorwarnung ab. Die anderen nehmen das zur Kenntnis und setzen die Simulation unbeirrt fort.
	Auf meinem Erstrechner erlaube ich nur noch die Nutzung eines einzigen Kerns, weil ich mir den Simulationsstatus mal ansehen will. Mit einem Live-Viewer kann ich - ähnlich wie bei einem YouTube-Video im bereits vorberechneten Teil der Simulation umherspringen und mich umschauen. Da mir gefällt was ich sehe, setze ich die beiden Kerne wieder aktiv und starte erneut meinen Zweitrecher. Diesmal soll er sich jedoch nicht an der Berechnung beteiligen, sondern, ein Video rendern. So geht das einige Tage weiter. Dann schaue ich mich erneut um und sehe, dass das System in einen stabilen Zustand übergegangen ist. Ich beende also lokal die Simulation. Meine Mitstreiter entscheiden sich jedoch, weiter zu rechnen. Auch mein Erstrechner beschäftigt von nun an 2 seiner Kerne damit, das Video zu rendern. Nach einem Tag erhalte ich die Meldung, dass beide Rechner fertig sind, und dass das Video nun bereitsteht.

	Diese Funktionalitäten erreichen wir folgendermaßen:
		Es ist davon auszugehen, dass zur Berechnung eines neuen Zustandes der alte Zustand in seiner Gänze vorliegen muss. Wir können also nicht die simulierte Zeit parallelisieren, sondern müssen zwischen den Zeitpunkten komplett synchron sein: Mehrere Agenten teilen sich den Zeitschritt und berechnen ihn aufgrund der Daten des vorrangegangenen Zeitschritts parallel. Erst wenn alle Agenten fertig sind, wird der nächste Zeitschritt in Angriff genommen.
		Ein Zeitschritt ist der Zeitraum zwischen zwei Stützstellen.
		
		Eine Simulation wird auf zwei verschiedene Arten parallelisiert: Zum einen stehen der Simulation mehrere Recheneinheiten zur Verfügung, die sich einen gemeinsamen Speicher teilen. Zum anderen ist das Simulationsobjekt Teil eines gerichteten Graphen von Simulationsobjekten, die sich ihren Speicher eben nicht teilen, sondern untereinander kommunizieren müssen.
		Das Simulationsobjekt hat Vorgänger (Knoten, die Daten liefern) und Nachfolger (Knoten, die Daten erhalten). In der Berechnung eines Zeitschrittes setzt das SO die ihm zu Verfügung stehenden Rechenkerne ein, um alle Nachfolger zu bedienen: Die Nachfolger geben alle bekannt, über welche Partikelpakete sie welche Informationen geliefert haben möchten. Das SO liefert diese Informationen, sobald es sie hat und zwar entweder, weil ein Vorgänger sie geliefert hat, oder weil es sie selbst berechnet hat. Diese Bekanntgabe oder "Bestellung" nennen wir Scope eines Berechnungsknotens. Er umfasst den Teilchenbereich und die Art der vom Knoten behandelten Teilcheninformationen (siehe auch weiter unten: Nicht alle Simulationsknoten besitzen alle Integratoren!), sowie die Zeitschritt-ID, für die die Informationen benötigt werden.
		Dabei werden die lokalen Kerne so gründlich wie möglich bzw. erlaubt ausgenutzt und es wird aufgrund einer dynamischen Performance-Schätzung der Rest der Daten von den Vorgängern verlangt. Das Berechnungsgrid verteilt seine Rechenlast auf diese Weise automatisch und dezentral.
		
		Die Integratoren werden also nur für die Teilchen aufgerufen, für die sich das SO im Grid zuständig fühlt. Trotzdem braucht jeder Knoten potenziell Informationen über *alle* Partikel des vergangenen Zeitschrittes. Die SO geben diese Informationen über's Netzwerk weiter. Diese Weitergabe muss so beschaffen sein, dass nur die nötigen Informationen weitergegeben werden: Beispielsweise könnte ein Knoten nur für die Gravitation einer Hälfte der Teilchen zuständig sein, nicht aber für ihre Kernreaktionen. Deshalb sollten für diesen Knoten auch nur die Informationen des Gravitationsintegrators übertragen werden und nicht die Informationen für den Kernreaktionsintegrator.
		Hieran wird deutlich: Obwohl alle Simulationsknoten alle Teilchen 
behandeln müssen, haben sie nicht alle die selben Integratoren.